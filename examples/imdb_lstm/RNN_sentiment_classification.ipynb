{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting sentiment on the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 15 17:15:32 CET 2017\r\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we show you how to train an RNN to classify movie review sentences. We mostly start from scratch, so that you should be able to plug in your own dataset without too much hassle. Furthermore, we explain some best practices with skorch, and how to perform a randomized hyper-parameter search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from dstoolbox.transformers import Padder2d\n",
    "from skorch import NeuralNetClassifier\n",
    "import torch\n",
    "from torch import nn\n",
    "F = nn.functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000  # This is on the low end\n",
    "MAX_LEN = 50  # Texts are pretty long on average, this is on the low end\n",
    "USE_CUDA = True  # Set this to False if you don't want to use CUDA\n",
    "NUM_CV_STEPS = 10  # Number of randomized search steps to perform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First make sure to install an additional package, dstoolbox\n",
    "\n",
    "    $ pip install dstoolbox\n",
    "\n",
    "Also, download the IMDB dataset\n",
    "\n",
    "    $ wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Untar and unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('aclImdb'):\n",
    "    # unzip data if it does not exist\n",
    "    with tarfile.open('aclImdb_v1.tar.gz', 'r:gz') as f:\n",
    "        f.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Movie Review Dataset v1.0\r\n",
      "\r\n",
      "Overview\r\n",
      "\r\n",
      "This dataset contains movie reviews along with their associated binary\r\n",
      "sentiment polarity labels. It is intended to serve as a benchmark for\r\n",
      "sentiment classification. This document outlines how the dataset was\r\n",
      "gathered, and how to use the files provided. \r\n"
     ]
    }
   ],
   "source": [
    "!head -n 8 aclImdb/README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@InProceedings{maas-EtAl:2011:ACL-HLT2011,\r\n",
      "  author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\r\n",
      "  title     = {Learning Word Vectors for Sentiment Analysis},\r\n",
      "  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\r\n",
      "  month     = {June},\r\n",
      "  year      = {2011},\r\n",
      "  address   = {Portland, Oregon, USA},\r\n",
      "  publisher = {Association for Computational Linguistics},\r\n",
      "  pages     = {142--150},\r\n",
      "  url       = {http://www.aclweb.org/anthology/P11-1015}\r\n",
      "}\r\n",
      "\r\n",
      "References\r\n",
      "\r\n",
      "Potts, Christopher. 2011. On the negativity of negation. In Nan Li and\r\n",
      "David Lutz, eds., Proceedings of Semantics and Linguistic Theory 20,\r\n",
      "636-659.\r\n",
      "\r\n",
      "Contact\r\n",
      "\r\n",
      "For questions/comments/corrections please contact Andrew Maas\r\n",
      "amaas@cs.stanford.edu\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 22 aclImdb/README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_files('aclImdb/train/', categories=['pos', 'neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only minimal data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mostly leave the data as is; for better reults, we should for instance remove markup, but we leave this out for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset['data'], dataset['target']\n",
    "X = np.asarray([x.decode() for x in X])  # decode from bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A peak at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: pos\n",
      "Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\n",
      "\n",
      "Target: neg\n",
      "Words can't describe how bad this movie is. I can't explain it by writing only. You have too see it for yourself to get at grip of how horrible a movie really can be. Not that I recommend you to do that. There are so many clichés, mistakes (and all other negative things you can imagine) here that will just make you cry. To start with the technical first, there are a LOT of mistakes regarding the airplane. I won't list them here, but just mention the coloring of the plane. They didn't even manage to show an airliner in the colors of a fictional airline, but instead used a 747 painted in the original Boeing livery. Very bad. The plot is stupid and has been done many times before, only much, much better. There are so many ridiculous moments here that i lost count of it really early. Also, I was on the bad guys' side all the time in the movie, because the good guys were so stupid. \"Executive Decision\" should without a doubt be you're choice over this one, even the \"Turbulence\"-movies are better. In fact, every other movie in the world is better than this one.\n",
      "\n",
      "Target: pos\n",
      "Everyone plays their part pretty well in this \"little nice movie\". Belushi gets the chance to live part of his life differently, but ends up realizing that what he had was going to be just as good or maybe even better. The movie shows us that we ought to take advantage of the opportunities we have, not the ones we do not or cannot have. If U can get this movie on video for around $10, it´d be an investment!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text, target in zip(X[:3], y):\n",
    "    print(\"Target: {}\".format(dataset['target_names'][target]))\n",
    "    print(text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many possible ways to transform our data so that we can pass it to our neural net. What we effectively need is to transform a list of strings to an array of indices, where each row corresponds to one sample, and in each row, each int represents a specific word.\n",
    "\n",
    "Below we show one way to achieve this that leverages sklearn's `CountVectorizer`. Here is its description from the sklearn documentation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Convert a collection of text documents to a matrix of token counts*\n",
    "\n",
    "*This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, it would seem that this is not what we need, but we can easily extract the indices for each row of the sparse matrix by calling `.nonzero()`. This is shown in the function below, which we will wrap into an sklearn `FunctionTransformer` later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def counts_to_indices(Xs):\n",
    "    return np.asarray([x.nonzero()[1] for x in Xs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, by using sklearn instead of rolling our own transformation code, we gain the following benefits:\n",
    "\n",
    "* battle-tested, (mostly) bug free code\n",
    "* since it is an sklearn transformer, we can put it into a `Pipeline`\n",
    "* many parameters for us to test in a hyper-parameter search\n",
    "\n",
    "For more on the last point, see the section about randomized search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have to solve a small problem, namely that sentences have different number of words. This results in a heterogenous array but we need a homogeneous array. With the help of dstoolbox's `Padder2d`, we get this functionality in an sklearn transformer. (Note: We set `pad_value=VOCAB_SIZE` to give the padded value a unique index, since the other indices will range from 0 to VOCAB_SIZE-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting all of this together, these are the transformation steps in the pipeline before the actual neural net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('counts', CountVectorizer(max_features=VOCAB_SIZE)),\n",
    "    ('to_idx', FunctionTransformer(counts_to_indices, accept_sparse=True)),\n",
    "    ('pad', Padder2d(max_len=MAX_LEN, pad_value=VOCAB_SIZE, dtype=int)),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the output looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92, 177, 209,  91,  75, 163, 106,  14,  13,   9,  70, 168, 155,\n",
       "        144, 194,  79, 179,  72,  61, 178,  25, 127,   2, 123,  68, 176,\n",
       "        154, 161,  85,   3,  12,  73, 180, 188, 122,  80,  31, 124, 149,\n",
       "        132, 101,  30,  53,  46, 214, 146,  51, 140,  98,  38],\n",
       "       [ 64,  69, 125, 192, 135, 145,  37,  59, 211, 164,  50,  66, 204,\n",
       "         82,  20, 167,  84, 134, 201,  10,  60,  45, 111, 121, 162, 126,\n",
       "         22, 189,  58,  21,  86, 172, 152, 198, 110,  28, 141, 147,   1,\n",
       "        197,  99,   5,  71,  42,   6,  11, 165, 114,  55, 150],\n",
       "       [100,   0,  15, 200,  96,  34, 136, 138,   4, 174, 143, 202, 196,\n",
       "        166, 116, 139,  16,  81,  88, 157, 195,  62,  56, 105,  90, 109,\n",
       "         36,  24, 131, 108, 203, 153, 148, 151,  65,  82, 134, 201,  11,\n",
       "        103,  78, 187,  33,  79, 179,  25,  85, 180,  31, 124]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline(steps).fit_transform(X[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As desired, we have a homogeneous array of indices, exactly what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a rather simple RNN with just embeddings, a single recurrent layer, and an output layer. To be later able to test all hyper-parameters, we make sure to pass them to the `__init__` of our pytorch module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dim=128,\n",
    "            rec_layer_type='lstm',\n",
    "            num_units=128,\n",
    "            dropout=0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.rec_layer_type = rec_layer_type.lower()\n",
    "        self.num_units = num_units\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.emb = nn.Embedding(VOCAB_SIZE + 1, embedding_dim=self.embedding_dim)\n",
    "        \n",
    "        rec_layer = {'lstm': nn.LSTM, 'gru': nn.GRU}[self.rec_layer_type]\n",
    "        # We have to make sure that the recurrent layer is batch_first,\n",
    "        # since sklearn assumes the batch dimension to be the first\n",
    "        self.rec = rec_layer(self.embedding_dim, self.num_units, batch_first=True)\n",
    "\n",
    "        self.output = nn.Linear(self.num_units, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        embeddings = self.emb(X)\n",
    "        # from the recurrent layer, only take the activities from the last sequence step\n",
    "        if self.rec_layer_type == 'gru':\n",
    "            _, rec_out = self.rec(embeddings)\n",
    "        else:\n",
    "            _, (rec_out, _) = self.rec(embeddings)\n",
    "        # dim 0 is seq dimension -> squeeze gets rid of it and thus makes the tensor batch_first\n",
    "        rec_out = rec_out.squeeze(0)\n",
    "        drop = F.dropout(rec_out, p=self.dropout)\n",
    "        # Remember that the final non-linearity should be softmax, so that our predict_proba\n",
    "        # method outputs actual probabilities!\n",
    "        out = F.softmax(self.output(drop))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wrap the pytorch module into a skorch `NeuralNetClassifier`, since we are dealing with a binary classification task, and append the step to our transformation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "steps.append(\n",
    "    ('net', NeuralNetClassifier(\n",
    "        ImdbNet,\n",
    "        use_cuda=USE_CUDA,\n",
    "        max_epochs=5,\n",
    "        lr=0.01,\n",
    "        optimizer=torch.optim.RMSprop,\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are good to go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6960\u001b[0m       \u001b[32m0.7590\u001b[0m        \u001b[35m0.5355\u001b[0m  3.7855\n",
      "      2        \u001b[36m0.4711\u001b[0m       \u001b[32m0.7900\u001b[0m        \u001b[35m0.4737\u001b[0m  3.5145\n",
      "      3        \u001b[36m0.3972\u001b[0m       \u001b[32m0.7958\u001b[0m        \u001b[35m0.4542\u001b[0m  3.0171\n",
      "      4        \u001b[36m0.3495\u001b[0m       \u001b[32m0.8026\u001b[0m        0.4699  3.7981\n",
      "      5        \u001b[36m0.3098\u001b[0m       0.7684        0.5149  3.6162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        str...ec): LSTM(128, 128, batch_first=True)\n",
       "    (output): Linear(in_features=128, out_features=2)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above were already okay, but we have many hyper-parameters, so of course we would like to know which ones are best. Therefore, we perform a randomized search. For those not aware, a randomized search is like a grid search, but instead of testing the parameters systematically, they are drawn randomly from a distribution. In practice, compared to grid search, randomized search will find you better parameter values in a shorter amount of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the randomized search, we turn off the net's verbosity to not clutter the notebook. Also, we set `train_split=None`. This is because we don't need an internal train/valid split, given that sklearn's `RandomizedSearchCV` already takes care of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        str...ec): LSTM(128, 128, batch_first=True)\n",
       "    (output): Linear(in_features=128, out_features=2)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.set_params(net__verbose=0, net__train_split=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to set the hyper-parameter range to test. With randomized search, we can either specify a list (mostly for discreet variables) or a scipy stats distribution, from which sklearn will sample automatically.\n",
    "\n",
    "As we can see below, we can extend the randomized search to not only cover the parameters we defined for our RNN, but also to cover the way we construct our vocabulary using sklearn's `CountVectorizer`. This is why we said earlier that we should use it instead of implementing it ourselves. As shown below, we test:\n",
    "\n",
    "* stop_words: whether to remove english stop words or not\n",
    "* lowercase: whether to turn all words lower-cased or not\n",
    "* ngram_range: whether to use word uni-grams or bi-grams\n",
    "\n",
    "Additionally, we test some hyper-parameters on the RNN module itself (e.g. LSTM vs GRU) and on the skorch `NeuralNetClassifier` (e.g. `max_epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'counts__stop_words': ['english', None],\n",
    "    'counts__lowercase': [False, True],\n",
    "    'counts__ngram_range': [(1, 1), (2, 2)],\n",
    "    'net__module__embedding_dim': stats.randint(32, 256 + 1),\n",
    "    'net__module__rec_layer_type': ['gru', 'lstm'],\n",
    "    'net__module__num_units': stats.randint(32, 256 + 1),\n",
    "    'net__module__dropout': stats.uniform(0, 0.9),\n",
    "    'net__lr': [10**(-stats.uniform(1, 5).rvs()) for _ in range(NUM_CV_STEPS)],\n",
    "    'net__max_epochs': [5, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our randomized search and start fitting.\n",
    "\n",
    "For demonstration purposes, we perform only a low number of iterations (10) and only fit on the first 1000 samples. Of course, with more time, we should try more steps and include all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(pipe, params, n_iter=NUM_CV_STEPS, verbose=2, refit=False, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=0.0791673882203, net__max_epochs=5, net__module__dropout=0.378566015198, net__module__embedding_dim=80, net__module__num_units=88, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=0.0791673882203, net__max_epochs=5, net__module__dropout=0.378566015198, net__module__embedding_dim=80, net__module__num_units=88, net__module__rec_layer_type=gru, total=   1.0s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=0.0791673882203, net__max_epochs=5, net__module__dropout=0.378566015198, net__module__embedding_dim=80, net__module__num_units=88, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.5s remaining:    0.0s\n",
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=0.0791673882203, net__max_epochs=5, net__module__dropout=0.378566015198, net__module__embedding_dim=80, net__module__num_units=88, net__module__rec_layer_type=gru, total=   1.0s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=0.0791673882203, net__max_epochs=5, net__module__dropout=0.378566015198, net__module__embedding_dim=80, net__module__num_units=88, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=0.0791673882203, net__max_epochs=5, net__module__dropout=0.378566015198, net__module__embedding_dim=80, net__module__num_units=88, net__module__rec_layer_type=gru, total=   1.0s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=5, net__module__dropout=0.315289932874, net__module__embedding_dim=37, net__module__num_units=126, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=5, net__module__dropout=0.315289932874, net__module__embedding_dim=37, net__module__num_units=126, net__module__rec_layer_type=gru, total=   1.1s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=5, net__module__dropout=0.315289932874, net__module__embedding_dim=37, net__module__num_units=126, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=5, net__module__dropout=0.315289932874, net__module__embedding_dim=37, net__module__num_units=126, net__module__rec_layer_type=gru, total=   1.1s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=5, net__module__dropout=0.315289932874, net__module__embedding_dim=37, net__module__num_units=126, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=5, net__module__dropout=0.315289932874, net__module__embedding_dim=37, net__module__num_units=126, net__module__rec_layer_type=gru, total=   1.1s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.0791673882203, net__max_epochs=10, net__module__dropout=0.416746337553, net__module__embedding_dim=180, net__module__num_units=96, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.0791673882203, net__max_epochs=10, net__module__dropout=0.416746337553, net__module__embedding_dim=180, net__module__num_units=96, net__module__rec_layer_type=lstm, total=   1.9s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.0791673882203, net__max_epochs=10, net__module__dropout=0.416746337553, net__module__embedding_dim=180, net__module__num_units=96, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.0791673882203, net__max_epochs=10, net__module__dropout=0.416746337553, net__module__embedding_dim=180, net__module__num_units=96, net__module__rec_layer_type=lstm, total=   1.9s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.0791673882203, net__max_epochs=10, net__module__dropout=0.416746337553, net__module__embedding_dim=180, net__module__num_units=96, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.0791673882203, net__max_epochs=10, net__module__dropout=0.416746337553, net__module__embedding_dim=180, net__module__num_units=96, net__module__rec_layer_type=lstm, total=   1.7s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=0.000242050137131, net__max_epochs=5, net__module__dropout=0.594059301552, net__module__embedding_dim=190, net__module__num_units=82, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=0.000242050137131, net__max_epochs=5, net__module__dropout=0.594059301552, net__module__embedding_dim=190, net__module__num_units=82, net__module__rec_layer_type=lstm, total=   0.9s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=0.000242050137131, net__max_epochs=5, net__module__dropout=0.594059301552, net__module__embedding_dim=190, net__module__num_units=82, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=0.000242050137131, net__max_epochs=5, net__module__dropout=0.594059301552, net__module__embedding_dim=190, net__module__num_units=82, net__module__rec_layer_type=lstm, total=   1.0s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=0.000242050137131, net__max_epochs=5, net__module__dropout=0.594059301552, net__module__embedding_dim=190, net__module__num_units=82, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(1, 1), counts__stop_words=english, net__lr=0.000242050137131, net__max_epochs=5, net__module__dropout=0.594059301552, net__module__embedding_dim=190, net__module__num_units=82, net__module__rec_layer_type=lstm, total=   1.1s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=10, net__module__dropout=0.682168832525, net__module__embedding_dim=167, net__module__num_units=189, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=10, net__module__dropout=0.682168832525, net__module__embedding_dim=167, net__module__num_units=189, net__module__rec_layer_type=gru, total=   1.9s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=10, net__module__dropout=0.682168832525, net__module__embedding_dim=167, net__module__num_units=189, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=10, net__module__dropout=0.682168832525, net__module__embedding_dim=167, net__module__num_units=189, net__module__rec_layer_type=gru, total=   1.7s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=10, net__module__dropout=0.682168832525, net__module__embedding_dim=167, net__module__num_units=189, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=10, net__module__dropout=0.682168832525, net__module__embedding_dim=167, net__module__num_units=189, net__module__rec_layer_type=gru, total=   1.8s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.79820757481, net__module__embedding_dim=186, net__module__num_units=80, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.79820757481, net__module__embedding_dim=186, net__module__num_units=80, net__module__rec_layer_type=gru, total=   1.8s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.79820757481, net__module__embedding_dim=186, net__module__num_units=80, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.79820757481, net__module__embedding_dim=186, net__module__num_units=80, net__module__rec_layer_type=gru, total=   1.9s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.79820757481, net__module__embedding_dim=186, net__module__num_units=80, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.79820757481, net__module__embedding_dim=186, net__module__num_units=80, net__module__rec_layer_type=gru, total=   1.7s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.369410361698, net__module__embedding_dim=113, net__module__num_units=206, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.369410361698, net__module__embedding_dim=113, net__module__num_units=206, net__module__rec_layer_type=lstm, total=   1.9s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.369410361698, net__module__embedding_dim=113, net__module__num_units=206, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.369410361698, net__module__embedding_dim=113, net__module__num_units=206, net__module__rec_layer_type=lstm, total=   1.9s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.369410361698, net__module__embedding_dim=113, net__module__num_units=206, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.369410361698, net__module__embedding_dim=113, net__module__num_units=206, net__module__rec_layer_type=lstm, total=   1.9s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.000242241225401, net__max_epochs=10, net__module__dropout=0.358315603328, net__module__embedding_dim=145, net__module__num_units=174, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.000242241225401, net__max_epochs=10, net__module__dropout=0.358315603328, net__module__embedding_dim=145, net__module__num_units=174, net__module__rec_layer_type=gru, total=   2.1s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.000242241225401, net__max_epochs=10, net__module__dropout=0.358315603328, net__module__embedding_dim=145, net__module__num_units=174, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.000242241225401, net__max_epochs=10, net__module__dropout=0.358315603328, net__module__embedding_dim=145, net__module__num_units=174, net__module__rec_layer_type=gru, total=   2.0s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.000242241225401, net__max_epochs=10, net__module__dropout=0.358315603328, net__module__embedding_dim=145, net__module__num_units=174, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=english, net__lr=0.000242241225401, net__max_epochs=10, net__module__dropout=0.358315603328, net__module__embedding_dim=145, net__module__num_units=174, net__module__rec_layer_type=gru, total=   1.8s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.575476741025, net__module__embedding_dim=199, net__module__num_units=210, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.575476741025, net__module__embedding_dim=199, net__module__num_units=210, net__module__rec_layer_type=lstm, total=   2.0s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.575476741025, net__module__embedding_dim=199, net__module__num_units=210, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.575476741025, net__module__embedding_dim=199, net__module__num_units=210, net__module__rec_layer_type=lstm, total=   2.1s\n",
      "[CV] counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.575476741025, net__module__embedding_dim=199, net__module__num_units=210, net__module__rec_layer_type=lstm \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=False, counts__ngram_range=(2, 2), counts__stop_words=None, net__lr=3.98968855269e-06, net__max_epochs=10, net__module__dropout=0.575476741025, net__module__embedding_dim=199, net__module__num_units=210, net__module__rec_layer_type=lstm, total=   2.1s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=5, net__module__dropout=0.691307357589, net__module__embedding_dim=190, net__module__num_units=217, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=5, net__module__dropout=0.691307357589, net__module__embedding_dim=190, net__module__num_units=217, net__module__rec_layer_type=gru, total=   1.2s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=5, net__module__dropout=0.691307357589, net__module__embedding_dim=190, net__module__num_units=217, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=5, net__module__dropout=0.691307357589, net__module__embedding_dim=190, net__module__num_units=217, net__module__rec_layer_type=gru, total=   1.1s\n",
      "[CV] counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=5, net__module__dropout=0.691307357589, net__module__embedding_dim=190, net__module__num_units=217, net__module__rec_layer_type=gru \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbossan_dev/anaconda3/envs/skorch/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  counts__lowercase=True, counts__ngram_range=(1, 1), counts__stop_words=None, net__lr=6.4534767546e-06, net__max_epochs=5, net__module__dropout=0.691307357589, net__module__embedding_dim=190, net__module__num_units=217, net__module__rec_layer_type=gru, total=   1.1s\n",
      "CPU times: user 58.1 s, sys: 1.58 s, total: 59.7 s\n",
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        str...ec): LSTM(128, 128, batch_first=True)\n",
       "    (output): Linear(in_features=128, out_features=2)\n",
       "  ),\n",
       "))]),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'counts__stop_words': ['english', None], 'counts__lowercase': [False, True], 'counts__ngram_range': [(1, 1), (2, 2)], 'net__module__embedding_dim': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc0eef855f8>, 'net__module__rec_layer_type': ['gru', 'lstm'], 'net__modul...0.00010767701730012674, 0.00024224122540093021, 6.4534767545970891e-06], 'net__max_epochs': [5, 10]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=False,\n",
       "          return_train_score=True, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time search.fit(X[:1000], y[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we see the best accuracy we achieved and what the best hyper-parameters were. Of course the scores here are underwhelming, given that we used so few samples and iterations. Using all the data and trying out more iterations should lead to much better outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.53400000000000003,\n",
       " {'counts__lowercase': True,\n",
       "  'counts__ngram_range': (1, 1),\n",
       "  'counts__stop_words': None,\n",
       "  'net__lr': 6.4534767545970891e-06,\n",
       "  'net__max_epochs': 5,\n",
       "  'net__module__dropout': 0.69130735758896922,\n",
       "  'net__module__embedding_dim': 190,\n",
       "  'net__module__num_units': 217,\n",
       "  'net__module__rec_layer_type': 'gru'})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
